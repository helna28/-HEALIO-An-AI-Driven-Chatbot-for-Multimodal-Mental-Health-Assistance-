{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coc8N6u8BblE",
        "outputId": "951aa895-b6e3-4e83-ef18-c4044af4beef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dszQobQCOXE",
        "outputId": "282a942b-3bf6-4fae-cf9c-019c800f1fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.12/dist-packages (3.14.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: deepface in /usr/local/lib/python3.12/dist-packages (0.0.95)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from deepface) (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (2.19.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.10.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from deepface) (3.1.2)\n",
            "Requirement already satisfied: flask-cors>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from deepface) (6.0.1)\n",
            "Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (1.0.0)\n",
            "Requirement already satisfied: retina-face>=0.0.14 in /usr/local/lib/python3.12/dist-packages (from deepface) (0.0.17)\n",
            "Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (0.7.1)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.12/dist-packages (from deepface) (23.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire>=0.4.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->deepface) (3.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gunicorn>=20.1.0->deepface) (25.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=2.2.0->deepface) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn>=0.1.0->deepface) (4.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->deepface) (2025.10.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->deepface) (2.19.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gtts) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2025.10.5)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install opencv-python\n",
        "!pip install deepface\n",
        "!pip install gtts\n",
        "!pip install openai-whisper moviepy gradio opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "3VrLHavf7aAg",
        "outputId": "7e60b1ba-2b41-4ad4-c695-cbe2e776796d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://14ddc823925bcc6d89.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://14ddc823925bcc6d89.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#true one\n",
        "import os\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import requests\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from gtts import gTTS\n",
        "import time\n",
        "\n",
        "# Function to transition from the logo page to the login page\n",
        "def show_login():\n",
        "    time.sleep(5)  # Pause for 3 seconds\n",
        "    return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "\n",
        "# Function to handle login\n",
        "def login(username, password):\n",
        "    if username == \"121\" and password == \"123\":\n",
        "        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True), \"âœ… Login Successful\"\n",
        "    else:\n",
        "        return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False), \"âŒ Invalid Credentials\"\n",
        "\n",
        "# Load Whisper model for audio and video transcription\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Load the fine-tuned GoEmotions model and tokenizer\n",
        "emotion_model_name = \"speedthrill/goemotions-finetuned\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)\n",
        "emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name)\n",
        "\n",
        "# Emotion labels\n",
        "emotion_labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "    'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
        "    'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
        "\n",
        "\n",
        "API_KEY = \"AIzaSyBa66toL3k0j5ySsxcTt3O9lXDrwtbJz5o\"\n",
        "GEMINI_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "# Store chat history globally\n",
        "chat_history = []\n",
        "def transcribe_audio_video(file_path):\n",
        "    if not file_path:\n",
        "        return \"\"\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"].strip()\n",
        "\n",
        "def detect_emotion(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = emotion_model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=-1)\n",
        "    top_emotions = torch.topk(probs, k=3)\n",
        "    detected_emotions = [(emotion_labels[i], float(probs[0][i])) for i in top_emotions.indices[0] if float(probs[0][i]) > 0.05]\n",
        "    return detected_emotions if detected_emotions else [(\"neutral\", 1.0)]\n",
        "\n",
        "def get_gemini_response(user_input, emotions):\n",
        "    history_text = \"\\n\".join([f\"User: {h[0]}\\nBot: {h[2]}\" for h in chat_history[-5:]])\n",
        "    top_emotion = emotions[0][0]\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are a supportive AI mental health chatbot.\\n\\n\"\n",
        "        f\"Chat History:\\n{history_text}\\n\\n\"\n",
        "        f\"The user is feeling {top_emotion} and said: '{user_input}'.\\n\"\n",
        "        f\"Provide an empathetic response and ask a relevant follow-up question.\"\n",
        "    )\n",
        "\n",
        "    payload = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_URL, headers=headers, json=payload)\n",
        "        response_data = response.json()\n",
        "        if 'candidates' in response_data:\n",
        "            return response_data['candidates'][0]['content']['parts'][0]['text']\n",
        "        return \"I'm here to listen. How are you feeling today?\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching AI response: {e}\"\n",
        "\n",
        "def text_to_speech(text):\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang=\"en\")\n",
        "        temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "        tts.save(temp_audio_file.name)\n",
        "        return temp_audio_file.name\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating speech: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_media(audio_file, video_file, text_input):\n",
        "    transcribed_text = \"\"\n",
        "    if audio_file:\n",
        "        transcribed_text += transcribe_audio_video(audio_file)\n",
        "    if video_file:\n",
        "        transcribed_text += \" \" + transcribe_audio_video(video_file)\n",
        "\n",
        "    text = text_input.strip() or transcribed_text.strip()\n",
        "    if not text:\n",
        "        return \"No input detected. Please provide text, audio, or video.\", \"\", \"\", \"\", \"\"\n",
        "\n",
        "    detected_emotions = detect_emotion(text)\n",
        "    emotions_text = \", \".join([f\"{e} ({round(c*100, 2)}%)\" for e, c in detected_emotions])\n",
        "    gemini_response = get_gemini_response(text, detected_emotions)\n",
        "\n",
        "    chat_history.append((text, emotions_text, gemini_response))\n",
        "    chat_history_text = \"\\n\".join([f\"User: {h[0]}\\nEmotion: {h[1]}\\nBot: {h[2]}\\n\" for h in chat_history])\n",
        "\n",
        "    audio_response_file = text_to_speech(gemini_response) or \"\"\n",
        "    return text, emotions_text, gemini_response, chat_history_text, audio_response_file\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    .gradio-container {height: 100vh !important;}\n",
        "    #chatbot-container {overflow-y: auto; max-height: 80vh; padding: 10px;}\n",
        "\"\"\") as demo:\n",
        "\n",
        "    logo_page = gr.Column(visible=True)\n",
        "    with logo_page:\n",
        "        gr.Markdown(\"<h1 style='text-align: center; font-size: 100px;'>ðŸ˜Š</h1>\")\n",
        "        gr.Markdown(\"<h1 style='text-align: center;'>HEALIO</h1>\")\n",
        "\n",
        "    login_page = gr.Column(visible=False)\n",
        "    with login_page:\n",
        "        gr.Markdown(\"<h1 style='text-align: center; font-size: 50px;'>ðŸ”‘</h1>\")\n",
        "        username = gr.Textbox(label=\"Username\")\n",
        "        password = gr.Textbox(label=\"Password\", type=\"password\")\n",
        "        login_btn = gr.Button(\"Login\")\n",
        "        login_status = gr.Markdown(\"\")\n",
        "\n",
        "    chatbot_page = gr.Column(visible=False, elem_id=\"chatbot-container\")\n",
        "    with chatbot_page:\n",
        "        gr.Markdown(\"# AI Mental Health Chatbot\")\n",
        "        with gr.Row():\n",
        "           with gr.Column(scale=2):  # Adjust column width\n",
        "              audio_input = gr.Audio(type=\"filepath\", label=\"Upload/Record Audio\")\n",
        "              video_input = gr.Video(label=\"Upload/Record Video\")\n",
        "              text_input = gr.Textbox(label=\"Enter Text\", placeholder=\"Type or upload media...\")\n",
        "              convert_button = gr.Button(\"Process & Get Response\")\n",
        "           with gr.Column(scale=3):  # Adjust column width\n",
        "            transcribed_text = gr.Textbox(label=\"Transcribed Text\", interactive=True, lines=2)\n",
        "            emotion_output = gr.Textbox(label=\"Detected Emotions\", interactive=True, lines=2)\n",
        "            gemini_response = gr.Textbox(label=\"AI Response\", interactive=True, lines=3)\n",
        "            chat_history_display = gr.Textbox(label=\"Chat History\", interactive=False, lines=5)\n",
        "            audio_output = gr.Audio(label=\"AI Voice Response\")\n",
        "\n",
        "\n",
        "        convert_button.click(process_media, inputs=[audio_input, video_input, text_input],\n",
        "                             outputs=[transcribed_text, emotion_output, gemini_response, chat_history_display, audio_output])\n",
        "\n",
        "    login_btn.click(login, inputs=[username, password], outputs=[logo_page, login_page, chatbot_page, login_status])\n",
        "    demo.load(show_login, inputs=None, outputs=[logo_page, login_page, chatbot_page])\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYkpB5Ep1-C-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVHP5Ex_JiaB",
        "outputId": "dfee93b5-0fcd-47b2-abb4-fc2d21810dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'scored_labels': [{'label': 'anger', 'score': 0.44229114055633545}, {'label': 'joy', 'score': 0.3081267476081848}, {'label': 'fear', 'score': 0.19250823557376862}, {'label': 'sadness', 'score': 0.039406463503837585}, {'label': 'love', 'score': 0.009154881350696087}, {'label': 'surprise', 'score': 0.008512601256370544}]}\n"
          ]
        }
      ],
      "source": [
        "#testing  of nlp cloud api\n",
        "import requests\n",
        "\n",
        "url = \"https://api.nlpcloud.io/v1/distilbert-base-uncased-emotion/sentiment\"\n",
        "api_key = \"732599939fada0bce741a604cbd3f0c5d4ebfb84\"  # Replace with your actual key\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Token {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"text\": \"hiiii\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "print(response.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpZDkZZC99A1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-h7juNt99DZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vij9KPSS99Hb"
      },
      "outputs": [],
      "source": [
        "#exp 2\n",
        "#implement basic image enchnacement operations such as histogram equalisation,morphological operations\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#load an image\n",
        "#loada smaple image\n",
        "image = cv2.imread('C:\\\\Users\\\\helna\\\\Downloads\\\\flow1.jpg', 0)\n",
        "  #load in grayscale\n",
        "#apply histogram equalisatiuom\n",
        "equalised_image=cv2.equalizeHist(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "Q-jje1Tc99I_",
        "outputId": "870e3180-e272-47ce-9bef-2c2b0ad878c6"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Image data of dtype object cannot be converted to float",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-698507298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3590\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3591\u001b[0m ) -> AxesImage:\n\u001b[0;32m-> 3592\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   3593\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3594\u001b[0m         \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             return func(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5943\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5945\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5946\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5947\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_image_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"same_kind\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             raise TypeError(f\"Image data of dtype {A.dtype} cannot be \"\n\u001b[0m\u001b[1;32m    639\u001b[0m                             f\"converted to float\")\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Display the original and equalised images\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(image,cmap='gray')\n",
        "plt.title('original image')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(equalised_image,cmap='gray')\n",
        "plt.title('Equalised image')\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(2,2,3)\n",
        "plt.hist(image)\n",
        "plt.title(' HIstogram of original image')\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(2,2,3)\n",
        "plt.hist(equalised_image)\n",
        "plt.title('Histogram of Equalised  image')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__erCg5p99LM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "CHeWGJwk99N1",
        "outputId": "76744d56-3540-49bc-d690-956c4250ef92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2e935195b4b82d96db.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://2e935195b4b82d96db.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import requests\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from gtts import gTTS\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Function to transition from the logo page to the login page\n",
        "def show_login():\n",
        "    time.sleep(5)  # Pause for 5 seconds\n",
        "    return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "\n",
        "# Function to handle login\n",
        "def login(username, password):\n",
        "    if username == \"admin\" and password == \"password\":\n",
        "        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True), \"âœ… Login Successful\"\n",
        "    else:\n",
        "        return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False), \"âŒ Invalid Credentials\"\n",
        "\n",
        "# Load Whisper model for audio transcription\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Load the fine-tuned GoEmotions model and tokenizer\n",
        "emotion_model_name = \"speedthrill/goemotions-finetuned\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)\n",
        "emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name)\n",
        "\n",
        "# Emotion labels\n",
        "emotion_labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "    'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
        "    'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
        "\n",
        "API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
        "GEMINI_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "# Store chat history globally\n",
        "chat_history = []\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    if not file_path:\n",
        "        return \"\"\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"].strip()\n",
        "\n",
        "def detect_emotion(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = emotion_model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=-1)\n",
        "    top_emotions = torch.topk(probs, k=3)\n",
        "    detected_emotions = [(emotion_labels[i], float(probs[0][i])) for i in top_emotions.indices[0] if float(probs[0][i]) > 0.05]\n",
        "    return detected_emotions if detected_emotions else [(\"neutral\", 1.0)]\n",
        "\n",
        "def get_gemini_response(user_input, emotions):\n",
        "    history_text = \"\\n\".join([f\"User: {h[0]}\\nBot: {h[2]}\" for h in chat_history[-5:]])\n",
        "    top_emotion = emotions[0][0]\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are a supportive AI mental health chatbot.\\n\\n\"\n",
        "        f\"Chat History:\\n{history_text}\\n\\n\"\n",
        "        f\"The user is feeling {top_emotion} and said: '{user_input}'.\\n\"\n",
        "        f\"Provide an empathetic response and ask a relevant follow-up question.\"\n",
        "    )\n",
        "\n",
        "    payload = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_URL, headers=headers, json=payload)\n",
        "        response_data = response.json()\n",
        "        if 'candidates' in response_data:\n",
        "            return response_data['candidates'][0]['content']['parts'][0]['text']\n",
        "        return \"I'm here to listen. How are you feeling today?\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching AI response: {e}\"\n",
        "\n",
        "def text_to_speech(text):\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang=\"en\")\n",
        "        temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "        tts.save(temp_audio_file.name)\n",
        "        return temp_audio_file.name\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating speech: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_media(audio_file, text_input):\n",
        "    transcribed_text = \"\"\n",
        "    if audio_file:\n",
        "        transcribed_text += transcribe_audio(audio_file)\n",
        "\n",
        "    text = text_input.strip() or transcribed_text.strip()\n",
        "    if not text:\n",
        "        return \"No input detected. Please provide text or audio.\", \"\", \"\", \"\", \"\"\n",
        "\n",
        "    detected_emotions = detect_emotion(text)\n",
        "    emotions_text = \", \".join([f\"{e} ({round(c*100, 2)}%)\" for e, c in detected_emotions])\n",
        "    gemini_response = get_gemini_response(text, detected_emotions)\n",
        "\n",
        "    chat_history.append((text, emotions_text, gemini_response))\n",
        "    chat_history_text = \"\\n\".join([f\"User: {h[0]}\\nEmotion: {h[1]}\\nBot: {h[2]}\\n\" for h in chat_history])\n",
        "\n",
        "    audio_response_file = text_to_speech(gemini_response) or \"\"\n",
        "    return text, emotions_text, gemini_response, chat_history_text, audio_response_file\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    .gradio-container {height: 100vh !important;}\n",
        "    #chatbot-container {overflow-y: auto; max-height: 80vh; padding: 10px;}\n",
        "\"\"\") as demo:\n",
        "\n",
        "    logo_page = gr.Column(visible=True)\n",
        "    with logo_page:\n",
        "        gr.Markdown(\"<h1 style='text-align: center; font-size: 100px;'>ðŸ˜Š</h1>\")\n",
        "        gr.Markdown(\"<h1 style='text-align: center;'>HEALIO</h1>\")\n",
        "\n",
        "    login_page = gr.Column(visible=False)\n",
        "    with login_page:\n",
        "        gr.Markdown(\"<h1 style='text-align: center; font-size: 50px;'>ðŸ”‘</h1>\")\n",
        "        username = gr.Textbox(label=\"Username\")\n",
        "        password = gr.Textbox(label=\"Password\", type=\"password\")\n",
        "        login_btn = gr.Button(\"Login\")\n",
        "        login_status = gr.Markdown(\"\")\n",
        "\n",
        "    chatbot_page = gr.Column(visible=False, elem_id=\"chatbot-container\")\n",
        "    with chatbot_page:\n",
        "        gr.Markdown(\"# AI Mental Health Chatbot\")\n",
        "        with gr.Row():\n",
        "           with gr.Column(scale=2):\n",
        "              audio_input = gr.Audio(type=\"filepath\", label=\"Upload/Record Audio\")\n",
        "              text_input = gr.Textbox(label=\"Enter Text\", placeholder=\"Type or speak...\")\n",
        "              convert_button = gr.Button(\"Process & Get Response\")\n",
        "           with gr.Column(scale=3):\n",
        "              transcribed_text = gr.Textbox(label=\"Transcribed Text\", interactive=True, lines=2)\n",
        "              emotion_output = gr.Textbox(label=\"Detected Emotions\", interactive=True, lines=2)\n",
        "              gemini_response = gr.Textbox(label=\"AI Response\", interactive=True, lines=3)\n",
        "              chat_history_display = gr.Textbox(label=\"Chat History\", interactive=False, lines=5)\n",
        "              audio_output = gr.Audio(label=\"AI Voice Response\")\n",
        "\n",
        "        convert_button.click(process_media, inputs=[audio_input, text_input],\n",
        "                             outputs=[transcribed_text, emotion_output, gemini_response, chat_history_display, audio_output])\n",
        "\n",
        "    login_btn.click(login, inputs=[username, password], outputs=[logo_page, login_page, chatbot_page, login_status])\n",
        "    demo.load(show_login, inputs=None, outputs=[logo_page, login_page, chatbot_page])\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrY9GfuG99Qk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9O5q-ft99TU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}